//
//  ChatViewModel.swift
//  speaking
//
//  Created by Randy on 24/9/2025.
//

import Foundation
import SwiftUI
import Combine
import AVFoundation

@MainActor
class ChatViewModel: ObservableObject {
    // MARK: - Published Properties
    @Published var messages: [Message] = []
    @Published var inputText = ""
    @Published var isRecording = false
    @Published var isLoading = false
    @Published var errorMessage: String?
    @Published var keyboardHeight: CGFloat = 0
    
    // MARK: - Properties
    private var cancellables = Set<AnyCancellable>()
    private let aiService: AIServiceProtocol
    private let audioPlayerService: AudioServiceProtocol
    private let streamingASRService: StreamingASRServiceProtocol
    private var currentRecordingURL: URL?
    
    // MARK: - Init
    init(
        aiService: AIServiceProtocol,
        audioPlayerService: AudioServiceProtocol,
        streamingASRService: StreamingASRServiceProtocol
    ) {
        self.aiService = aiService
        self.audioPlayerService = audioPlayerService
        self.streamingASRService = streamingASRService
        setupInitialMessage()
        setupKeyboardObservers()
        setupStreamingASRCallbacks()
    }
    
    deinit {
        NotificationCenter.default.removeObserver(self)
    }
    
    // MARK: - Public Methods
    func sendMessage() {
        guard !inputText.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty else { return }
        
        let userMessage = Message(text: inputText, isFromUser: true)
        messages.append(userMessage)
        inputText = ""
        processConversation()
    }
    
    func startRecording() {
        guard !isRecording else { return }
        
        // ç«‹å³æ›´æ–°UIçŠ¶æ€ï¼Œæä¾›å³æ—¶åé¦ˆ
        isRecording = true
        print("[Voice] å¼€å§‹æµå¼è¯­éŸ³è¯†åˆ«")
        
        Task {
            do {
                try await streamingASRService.startStreaming()
                print("[Voice] æµå¼è¯†åˆ«å·²å¯åŠ¨")
            } catch {
                await MainActor.run {
                    self.isRecording = false
                    self.errorMessage = "å¼€å§‹è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼š\(error.localizedDescription)"
                }
                print("[Voice][Error] startStreaming failed: \(error)")
            }
        }
    }
    
    func stopRecording() {
        guard isRecording else {
            print("[Voice] stopRecording ignored, isRecording = false")
            return
        }
        
        isRecording = false
        print("[Voice] æ‰‹åŠ¨åœæ­¢æµå¼è¯†åˆ«")
        
        Task {
            do {
                try await streamingASRService.stopStreaming()
                print("[Voice] æµå¼è¯†åˆ«å·²åœæ­¢")
            } catch {
                await MainActor.run {
                    self.errorMessage = "åœæ­¢è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼š\(error.localizedDescription)"
                }
                print("[Voice][Error] stopStreaming failed: \(error)")
            }
        }
    }
    
    func cancelRecording() {
        guard isRecording else { return }
        
        // ç«‹å³æ›´æ–°UIçŠ¶æ€
        isRecording = false
        print("[Voice] å–æ¶ˆæµå¼è¯†åˆ«")
        
        Task {
            do {
                try await streamingASRService.stopStreaming()
                print("[Voice] æµå¼è¯†åˆ«å·²å–æ¶ˆ")
            } catch {
                print("[Voice][Error] å–æ¶ˆæµå¼è¯†åˆ«å¤±è´¥: \(error)")
            }
        }
    }
    
    func clearChat() {
        messages = []
        setupInitialMessage()
    }
    
    func shareChat() {
        let chatText = messages.map { message in
            let sender = message.isFromUser ? "ç”¨æˆ·" : "AI"
            return "\(sender): \(message.text)"
        }.joined(separator: "\n")
        
        let activityViewController = UIActivityViewController(activityItems: [chatText], applicationActivities: nil)
        
        if let windowScene = UIApplication.shared.connectedScenes.first as? UIWindowScene,
           let window = windowScene.windows.first {
            window.rootViewController?.present(activityViewController, animated: true)
        }
    }
    
    func playAudio(url: URL) {
        Task {
            try await audioPlayerService.playAudio(url)
        }
    }
    
    // MARK: - Private Methods
    private func setupInitialMessage() {
        let welcomeMessage = Message(
            text: "Hey! Welcome to your personal language dojo! ğŸ¯ I'm LiY, your dedicated practice partner. Before we start, tell me: which language would you like to practice today? What's your approximate level (e.g., A1 beginner, B2 intermediate)? Any specific topics you're keen to chat about, like food, travel, or the latest movies? Don't be shy, let me know! ğŸ˜Š",
            isFromUser: false
        )
        messages = [welcomeMessage]
    }
    
    private func setupKeyboardObservers() {
        NotificationCenter.default.publisher(for: UIResponder.keyboardWillShowNotification)
            .sink { [weak self] notification in
                if let keyboardSize = notification.userInfo?[UIResponder.keyboardFrameEndUserInfoKey] as? NSValue {
                    self?.keyboardHeight = keyboardSize.cgRectValue.height
                }
            }
            .store(in: &cancellables)
        
        NotificationCenter.default.publisher(for: UIResponder.keyboardWillHideNotification)
            .sink { [weak self] _ in
                self?.keyboardHeight = 0
            }
            .store(in: &cancellables)
    }
    
    private func setupStreamingASRCallbacks() {
        // éƒ¨åˆ†è¯†åˆ«ç»“æœå›è°ƒï¼ˆç«‹å³è§¦å‘ç•Œé¢å…³é—­ï¼‰
        streamingASRService.onPartialResult = { [weak self] partialText in
            print("[StreamASR] æ£€æµ‹åˆ°æ–­å¥ï¼Œç«‹å³å…³é—­ç•Œé¢: \(partialText)")
            Task {
                await MainActor.run {
                    self?.isRecording = false  // ç«‹å³å…³é—­è¯­éŸ³ç•Œé¢
                }
            }
        }
        
        // æœ€ç»ˆè¯†åˆ«ç»“æœå›è°ƒï¼ˆåå°è¯†åˆ«å®Œæˆï¼Œæ·»åŠ æ¶ˆæ¯å¹¶è§¦å‘AIå›å¤ï¼‰
        streamingASRService.onFinalResult = { [weak self] finalText in
            print("[StreamASR] åå°è¯†åˆ«å®Œæˆ: \(finalText)")
            Task {
                await MainActor.run {
                    guard let self = self else { return }
                    
                    if !finalText.isEmpty {
                        let userMessage = Message(text: finalText, isFromUser: true)
                        self.messages.append(userMessage)
                        self.processConversation() // è‡ªåŠ¨è§¦å‘AIå›å¤
                    }
                }
            }
        }
        
        // é”™è¯¯å¤„ç†å›è°ƒ
        streamingASRService.onError = { [weak self] error in
            print("[StreamASR][Error] \(error.localizedDescription)")
            Task {
                await MainActor.run {
                    self?.isRecording = false
                    self?.errorMessage = "è¯­éŸ³è¯†åˆ«é”™è¯¯ï¼š\(error.localizedDescription)"
                }
            }
        }
    }
    
    private func processConversation() {
        isLoading = true
        Task {
            do {
                let aiResponse = try await aiService.generateResponse(messages: messages)
                let aiMessage = Message(text: aiResponse.text, isFromUser: false, audioURL: aiResponse.audioURL)
                await MainActor.run {
                    withAnimation(.easeInOut(duration: 0.3)) {
                        self.messages.append(aiMessage)
                    }
                    self.isLoading = false
                }
            } catch {
                await MainActor.run {
                    let errorMessage = Message(
                        text: "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›å¤ã€‚è¯·ç¨åå†è¯•ã€‚",
                        isFromUser: false
                    )
                    self.messages.append(errorMessage)
                    self.isLoading = false
                    self.errorMessage = error.localizedDescription
                }
                print("[Voice][Error] processConversation failed: \(error)")
            }
        }
    }
}

// MARK: - Protocols
protocol AIServiceProtocol {
    func generateResponse(messages: [Message]) async throws -> AIResponse
}

protocol AudioServiceProtocol {
    func playAudio(_ audioURL: URL) async throws
}

// MARK: - AI Response Model
struct AIResponse {
    let text: String
    let audioURL: URL?
}

// MARK: - Mock Implementations
class AIService: AIServiceProtocol {
    func generateResponse(messages: [Message]) async throws -> AIResponse {
        try await Task.sleep(nanoseconds: 1_500_000_000)
        let fallbackText = [
            "å¾ˆå¥½çš„è¡¨è¾¾ï¼è®©æˆ‘ä»¬ç»§ç»­ç»ƒä¹ ã€‚",
            "è¿™æ˜¯ä¸€ä¸ªä¸é”™çš„è¯é¢˜ï¼Œä½ å¯ä»¥æä¾›æ›´å¤šç»†èŠ‚å—ï¼Ÿ",
            "ä½ çš„å‘éŸ³å¬èµ·æ¥å¾ˆè‡ªç„¶ï¼Œä¿æŒè¿™ä¸ªçŠ¶æ€ã€‚"
        ].randomElement() ?? "å¥½çš„ï¼Œæˆ‘ä»¬ç»§ç»­ã€‚"
        return AIResponse(text: fallbackText, audioURL: nil)
    }
}

class AudioService: AudioServiceProtocol {
    private var player: AVAudioPlayer?
    
    func playAudio(_ audioURL: URL) async throws {
        let data = try Data(contentsOf: audioURL)
        player = try AVAudioPlayer(data: data)
        player?.play()
    }
}
