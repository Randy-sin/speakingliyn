//
//  StreamingASRService.swift
//  speaking
//
//  Created by Randy on 25/9/2025.
//

import Foundation
@preconcurrency import AVFoundation

protocol StreamingASRServiceProtocol: AnyObject {
    func startStreaming() async throws
    func stopStreaming() async throws
    
    var onPartialResult: ((String) -> Void)? { get set }
    var onFinalResult: ((String) -> Void)? { get set }
    var onError: ((Error) -> Void)? { get set }
}

// MARK: - åŸºäºVADæ–­å¥çš„æµå¼ASRæœåŠ¡
@MainActor
final class StreamingASRService: NSObject, StreamingASRServiceProtocol {
    
    // å›è°ƒ
    var onPartialResult: ((String) -> Void)?
    var onFinalResult: ((String) -> Void)?
    var onError: ((Error) -> Void)?
    
    // æ ¸å¿ƒæœåŠ¡
    private let asrService: QwenASRServiceProtocol
    private let fileUploadService: FileUploadServiceProtocol
    
    // éŸ³é¢‘å¼•æ“
    private var audioEngine: AVAudioEngine?
    private var inputNode: AVAudioInputNode?
    private var audioRecorder: AVAudioRecorder?
    
    // VADå‚æ•°ï¼ˆä¸¥æ ¼æ£€æµ‹ç‰ˆï¼‰
    private var dynamicSilenceThreshold: Float = 0.008  // åŠ¨æ€é™éŸ³é˜ˆå€¼ï¼Œå‚è€ƒå®˜æ–¹æ¨è
    private let silenceDuration: TimeInterval = 1.0     // ç¼©çŸ­ä¸º1ç§’ï¼Œæ›´å¿«å“åº”
    private let minSpeechDuration: TimeInterval = 0.3   // æœ€çŸ­0.3ç§’ï¼Œé¿å…è¯¯è§¦
    private let thresholdAdaptationRate: Float = 0.1    // é˜ˆå€¼è‡ªé€‚åº”é€Ÿç‡
    
    // çŠ¶æ€è·Ÿè¸ª
    private var isStreaming = false
    private var speechStartTime: Date?
    private var lastSpeechTime: Date?
    private var silenceStartTime: Date?  // æ–°å¢ï¼šé™éŸ³å¼€å§‹æ—¶é—´
    private var currentRecordingURL: URL?
    private var vadCheckTimer: Timer?  // æ–°å¢ï¼šå®šæœŸæ£€æŸ¥VADçŠ¶æ€çš„Timer
    
    // éŸ³é‡ç›‘æ§
    private var audioLevel: Float = 0.0
    private let smoothingFactor: Float = 0.2
    private var recentAudioLevels: [Float] = [] // ç”¨äºæ›´å‡†ç¡®çš„é™éŸ³æ£€æµ‹
    private var backgroundNoiseLevel: Float = 0.0 // èƒŒæ™¯å™ªéŸ³æ°´å¹³
    private var speechPeakLevel: Float = 0.0      // è¯­éŸ³å³°å€¼æ°´å¹³
    private var consecutiveSilenceCount: Int = 0   // è¿ç»­é™éŸ³æ£€æµ‹æ¬¡æ•°
    
    init(asrService: QwenASRServiceProtocol = QwenASRService(), fileUploadService: FileUploadServiceProtocol = FileUploadService()) {
        self.asrService = asrService
        self.fileUploadService = fileUploadService
        super.init()
    }
    
    func startStreaming() async throws {
        guard !isStreaming else { return }
        
        print("[StreamASR] å¼€å§‹VADè¯­éŸ³è¯†åˆ«ï¼ˆä¼˜åŒ–ç‰ˆï¼‰")
        
        // è¯·æ±‚éº¦å…‹é£æƒé™ (ç®€åŒ–å¤„ç†ï¼Œé¿å…iOSç‰ˆæœ¬å…¼å®¹é—®é¢˜)
        let session = AVAudioSession.sharedInstance()
        if session.recordPermission != .granted {
            print("[StreamASR] è¯·æ±‚éº¦å…‹é£æƒé™...")
            let granted = await withCheckedContinuation { continuation in
                session.requestRecordPermission { granted in
                    continuation.resume(returning: granted)
                }
            }
            if !granted {
                throw NSError(domain: "StreamingASRService", code: -1, userInfo: [NSLocalizedDescriptionKey: "éœ€è¦éº¦å…‹é£æƒé™"])
            }
        }
        
        try await setupAudioSession()
        try await setupAudioEngine()
        try await startRecording()
        
        isStreaming = true
        speechStartTime = nil
        lastSpeechTime = nil
        silenceStartTime = nil
        audioLevel = 0.0
        recentAudioLevels = []
        backgroundNoiseLevel = 0.0
        speechPeakLevel = 0.0
        consecutiveSilenceCount = 0
        dynamicSilenceThreshold = 0.015  // æé«˜åˆå§‹é˜ˆå€¼
        
        // å¯åŠ¨å®šæœŸVADæ£€æŸ¥
        vadCheckTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] _ in
            Task {
                await self?.checkVADStatus()
            }
        }
        
        print("[StreamASR] VADè¯­éŸ³è¯†åˆ«å·²å¯åŠ¨ï¼Œç­‰å¾…è¯­éŸ³...")
    }
    
    func stopStreaming() async throws {
        guard isStreaming else { return }
        
        isStreaming = false
        
        // åœæ­¢éŸ³é¢‘å¼•æ“
        audioEngine?.stop()
        audioEngine?.inputNode.removeTap(onBus: 0)
        audioEngine = nil
        inputNode = nil
        
        // åœæ­¢å½•éŸ³
        audioRecorder?.stop()
        audioRecorder = nil
        
        // å–æ¶ˆå®šæ—¶å™¨
        vadCheckTimer?.invalidate()
        vadCheckTimer = nil
        
        // å¤„ç†æœ€ç»ˆç»“æœ
        if let recordingURL = currentRecordingURL {
            await processRecording(url: recordingURL, isFinal: true)
        }
        
        print("[StreamASR] VADè¯­éŸ³è¯†åˆ«å·²åœæ­¢")
    }
    
    // MARK: - éŸ³é¢‘è®¾ç½®
    
    private func setupAudioSession() async throws {
        let session = AVAudioSession.sharedInstance()
        try session.setCategory(.playAndRecord, mode: .default, options: [.defaultToSpeaker, .allowBluetoothA2DP])
        try session.setActive(true)
        print("[StreamASR] éŸ³é¢‘ä¼šè¯é…ç½®æˆåŠŸ")
    }
    
    private func setupAudioEngine() async throws {
        audioEngine = AVAudioEngine()
        guard let audioEngine = audioEngine else {
            throw NSError(domain: "StreamingASRService", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ— æ³•åˆ›å»ºéŸ³é¢‘å¼•æ“"])
        }
        
        inputNode = audioEngine.inputNode
        let inputFormat = inputNode?.outputFormat(forBus: 0)
        
        // å®‰è£…éŸ³é¢‘ç›‘å¬tapï¼ˆç”¨äºVADæ£€æµ‹ï¼‰
        inputNode?.installTap(onBus: 0, bufferSize: 1024, format: inputFormat) { [weak self] buffer, _ in
            Task {
                await self?.processAudioBuffer(buffer)
            }
        }
        
        audioEngine.prepare()
        try audioEngine.start()
        print("[StreamASR] éŸ³é¢‘å¼•æ“å¯åŠ¨æˆåŠŸ")
    }
    
    private func startRecording() async throws {
        let tempURL = FileManager.default.temporaryDirectory.appendingPathComponent("vad_stream_\(UUID().uuidString).m4a")
        
        let settings: [String: Any] = [
            AVFormatIDKey: Int(kAudioFormatMPEG4AAC),
            AVSampleRateKey: 16000,
            AVNumberOfChannelsKey: 1,
            AVEncoderAudioQualityKey: AVAudioQuality.medium.rawValue
        ]
        
        audioRecorder = try AVAudioRecorder(url: tempURL, settings: settings)
        audioRecorder?.record()
        currentRecordingURL = tempURL
        
        print("[StreamASR] å¼€å§‹å½•éŸ³åˆ°æ–‡ä»¶: \(tempURL.lastPathComponent)")
    }
    
    // MARK: - VADéŸ³é¢‘å¤„ç†ï¼ˆç®€åŒ–ç‰ˆï¼‰
    
    private func processAudioBuffer(_ buffer: AVAudioPCMBuffer) async {
        guard isStreaming else { return }
        
        // è®¡ç®—å½“å‰éŸ³é¢‘çº§åˆ«
        let currentLevel = calculateAudioLevel(buffer)
        
        // åº”ç”¨å¹³æ»‘æ»¤æ³¢
        audioLevel = audioLevel * (1 - smoothingFactor) + currentLevel * smoothingFactor
        
        // ä¿å­˜æœ€è¿‘çš„éŸ³é¢‘çº§åˆ«ç”¨äºæ›´å‡†ç¡®çš„åˆ¤æ–­
        recentAudioLevels.append(audioLevel)
        if recentAudioLevels.count > 10 {
            recentAudioLevels.removeFirst()
        }
    }
    
    private func checkVADStatus() async {
        guard isStreaming else { return }
        
        let now = Date()
        let avgLevel = recentAudioLevels.isEmpty ? 0.0 : recentAudioLevels.reduce(0, +) / Float(recentAudioLevels.count)
        
        // åŠ¨æ€å­¦ä¹ èƒŒæ™¯å™ªéŸ³æ°´å¹³ï¼ˆåœ¨æ²¡æœ‰è¯­éŸ³æ—¶æŒç»­å­¦ä¹ ï¼‰
        if speechStartTime == nil {
            if backgroundNoiseLevel == 0.0 {
                backgroundNoiseLevel = avgLevel
                dynamicSilenceThreshold = max(backgroundNoiseLevel * 3.0, 0.015) // æé«˜åˆ°3å€ï¼Œæœ€å°é˜ˆå€¼0.015
                print("[StreamASR] ğŸ“Š å­¦ä¹ èƒŒæ™¯å™ªéŸ³: \(String(format: "%.4f", backgroundNoiseLevel)), åŠ¨æ€é˜ˆå€¼: \(String(format: "%.4f", dynamicSilenceThreshold))")
            } else {
                // æŒç»­æ›´æ–°èƒŒæ™¯å™ªéŸ³æ°´å¹³
                backgroundNoiseLevel = backgroundNoiseLevel * 0.98 + avgLevel * 0.02
                dynamicSilenceThreshold = max(backgroundNoiseLevel * 3.0, 0.015) // æé«˜å€æ•°å’Œæœ€å°é˜ˆå€¼
            }
        }
        
        // è®¡ç®—éŸ³é‡å˜åŒ–ç‡ï¼ˆæ£€æµ‹æ˜¯å¦æœ‰è¯­éŸ³æ´»åŠ¨ï¼‰
        let volumeVariation = recentAudioLevels.count > 1 ? 
            abs(recentAudioLevels.last! - recentAudioLevels[recentAudioLevels.count-2]) : 0.0
        
        // è®¡ç®—æœ€è¿‘å‡ å¸§çš„å¹³å‡å˜åŒ–ç‡ï¼ˆæ›´å‡†ç¡®çš„æ´»åŠ¨æ£€æµ‹ï¼‰
        let recentVariations = recentAudioLevels.count >= 3 ? 
            (0..<min(recentAudioLevels.count-1, 3)).map { i in
                abs(recentAudioLevels[recentAudioLevels.count-1-i] - recentAudioLevels[recentAudioLevels.count-2-i])
            } : [volumeVariation]
        let avgVariation = recentVariations.reduce(0, +) / Float(recentVariations.count)
        
        // æ›´ä¸¥æ ¼çš„è¯­éŸ³æ£€æµ‹ï¼šéœ€è¦æ˜æ˜¾çš„éŸ³é‡å˜åŒ–æ‰ç®—è¯­éŸ³
        let isLoudEnough = avgLevel > dynamicSilenceThreshold
        let hasSignificantVariation = avgVariation > 0.008  // æé«˜å˜åŒ–ç‡é˜ˆå€¼
        
        // è¯­éŸ³ç»“æŸæ£€æµ‹ï¼šå¦‚æœå½“å‰éŸ³é‡æ¯”å³°å€¼ä¸‹é™å¾ˆå¤šï¼Œä¹Ÿè®¤ä¸ºå¯èƒ½æ˜¯è¯­éŸ³ç»“æŸ
        let peakDropDetection = speechPeakLevel > 0.02 && (avgLevel < speechPeakLevel * 0.4)
        
        let isSpeaking = isLoudEnough && hasSignificantVariation && !peakDropDetection
        
        // æ›´æ–°è¯­éŸ³å³°å€¼æ°´å¹³
        if isSpeaking && avgLevel > speechPeakLevel {
            speechPeakLevel = avgLevel
        }
        
        print("[StreamASR] ğŸ”Š éŸ³é‡: \(String(format: "%.4f", avgLevel)), é˜ˆå€¼: \(String(format: "%.4f", dynamicSilenceThreshold)), å˜åŒ–: \(String(format: "%.4f", avgVariation)), å³°å€¼: \(String(format: "%.4f", speechPeakLevel)), è¯´è¯: \(isSpeaking)")
        
        if isSpeaking {
            // æ£€æµ‹åˆ°è¯­éŸ³æ´»åŠ¨
            consecutiveSilenceCount = 0
            
            if speechStartTime == nil {
                speechStartTime = now
                print("[StreamASR] ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹! (å³°å€¼: \(String(format: "%.4f", speechPeakLevel)))")
            }
            lastSpeechTime = now
            silenceStartTime = nil  // é‡ç½®é™éŸ³å¼€å§‹æ—¶é—´
            
        } else {
            // å¯èƒ½æ˜¯é™éŸ³
            consecutiveSilenceCount += 1
            
            // éœ€è¦è¿ç»­å¤šæ¬¡æ£€æµ‹åˆ°é™éŸ³æ‰ç¡®è®¤ï¼ˆå‡å°‘è¯¯åˆ¤ï¼‰
            if let speechStart = speechStartTime, consecutiveSilenceCount >= 3 {
                if silenceStartTime == nil {
                    silenceStartTime = now
                    print("[StreamASR] ğŸ”‡ ç¡®è®¤é™éŸ³å¼€å§‹... (è¿ç»­é™éŸ³æ£€æµ‹: \(consecutiveSilenceCount)æ¬¡)")
                }
                
                let currentSilenceDuration = now.timeIntervalSince(silenceStartTime!)
                print("[StreamASR] â° é™éŸ³æ—¶é•¿: \(String(format: "%.1f", currentSilenceDuration))s / \(silenceDuration)s")
                
                // æ£€æŸ¥æ˜¯å¦è¾¾åˆ°é™éŸ³é˜ˆå€¼
                if currentSilenceDuration >= silenceDuration {
                    let speechDuration = (lastSpeechTime ?? now).timeIntervalSince(speechStart)
                    
                    if speechDuration >= minSpeechDuration {
                        print("[StreamASR] âœ… è¾¾åˆ°é™éŸ³é˜ˆå€¼ï¼Œè‡ªåŠ¨ç»“æŸè¯†åˆ«ï¼è¯­éŸ³æ—¶é•¿: \(String(format: "%.1f", speechDuration))s, å³°å€¼: \(String(format: "%.4f", speechPeakLevel))")
                        await handleAutoEnd()
                    } else {
                        print("[StreamASR] â±ï¸ è¯­éŸ³å¤ªçŸ­(\(String(format: "%.1f", speechDuration))s)ï¼Œç»§ç»­ç­‰å¾…...")
                        // é‡ç½®çŠ¶æ€ç»§ç»­ç­‰å¾…
                        speechStartTime = nil
                        lastSpeechTime = nil
                        silenceStartTime = nil
                        consecutiveSilenceCount = 0
                        speechPeakLevel = 0.0
                    }
                }
            }
        }
    }
    
    private func handleAutoEnd() async {
        print("[StreamASR] ğŸ¯ è‡ªåŠ¨æ–­å¥è§¦å‘ï¼")
        
        // ç«‹å³è§¦å‘ç•Œé¢å…³é—­å›è°ƒ
        onPartialResult?("æ£€æµ‹åˆ°æ–­å¥ï¼Œæ­£åœ¨è¯†åˆ«...")
        
        // åœ¨åå°å¤„ç†ASRè¯†åˆ«
        Task {
            await self.processRecordingInBackground()
        }
        
        // ç«‹å³åœæ­¢å½•éŸ³çŠ¶æ€
        try? await stopStreaming()
    }
    
    private func processRecordingInBackground() async {
        guard let recordingURL = currentRecordingURL else { return }
        
        print("[StreamASR] ğŸ”„ åå°å¤„ç†å½•éŸ³è¯†åˆ«...")
        
        do {
            // æ£€æŸ¥æ–‡ä»¶å¤§å°
            let fileSize = try FileManager.default.attributesOfItem(atPath: recordingURL.path)[.size] as? Int ?? 0
            print("[StreamASR] å½•éŸ³æ–‡ä»¶å¤§å°: \(fileSize) bytes")
            
            if fileSize < 1000 {
                print("[StreamASR] å½•éŸ³æ–‡ä»¶å¤ªå°ï¼Œå–æ¶ˆè¯†åˆ«")
                onError?(NSError(domain: "StreamingASRService", code: -1, userInfo: [NSLocalizedDescriptionKey: "å½•éŸ³æ–‡ä»¶å¤ªå°"]))
                return
            }
            
            // åå°è°ƒç”¨ASRæœåŠ¡è¯†åˆ«
            let text = try await asrService.transcribe(audioURL: recordingURL, language: "zh")
            
            if !text.isEmpty {
                print("[StreamASR] âœ… åå°è¯†åˆ«å®Œæˆ: \(text)")
                onFinalResult?(text)
            } else {
                print("[StreamASR] âŒ åå°è¯†åˆ«ç»“æœä¸ºç©º")
                onError?(NSError(domain: "StreamingASRService", code: -2, userInfo: [NSLocalizedDescriptionKey: "æ²¡æœ‰è¯†åˆ«åˆ°è¯­éŸ³å†…å®¹"]))
            }
            
            // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try? FileManager.default.removeItem(at: recordingURL)
            
        } catch {
            print("[StreamASR][Error] åå°è¯†åˆ«å¤±è´¥: \(error)")
            onError?(error)
        }
    }
    
    private func calculateAudioLevel(_ buffer: AVAudioPCMBuffer) -> Float {
        guard let channelData = buffer.floatChannelData?[0] else { return 0.0 }
        
        var sum: Float = 0.0
        let frameLength = Int(buffer.frameLength)
        
        for i in 0..<frameLength {
            sum += abs(channelData[i])
        }
        
        return frameLength > 0 ? sum / Float(frameLength) : 0.0
    }
    
    private func processRecording(url: URL, isFinal: Bool) async {
        // è¿™ä¸ªæ–¹æ³•ç°åœ¨ä¸»è¦ç”¨äºæ‰‹åŠ¨åœæ­¢çš„æƒ…å†µ
        if isFinal {
            await processRecordingInBackground()
        }
    }
}
