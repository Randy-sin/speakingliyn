//
//  StreamingASRService.swift
//  speaking
//
//  Created by Randy on 25/9/2025.
//

import Foundation
import AVFoundation

protocol StreamingASRServiceProtocol: AnyObject {
    func startStreaming() async throws
    func stopStreaming() async throws
    
    var onPartialResult: ((String) -> Void)? { get set }
    var onFinalResult: ((String) -> Void)? { get set }
    var onError: ((Error) -> Void)? { get set }
}

// MARK: - æŒ‰ç…§Fun-ASRæ–‡æ¡£ä¼˜åŒ–çš„è¯­éŸ³è¯†åˆ«
final class StreamingASRService: NSObject, StreamingASRServiceProtocol, @unchecked Sendable {
    
    // å›žè°ƒ
    var onPartialResult: ((String) -> Void)?
    var onFinalResult: ((String) -> Void)?
    var onError: ((Error) -> Void)?
    
    // æœåŠ¡ä¾èµ–
    private let asrService: QwenASRServiceProtocol
    private let fileUploadService: FileUploadServiceProtocol
    
    // å½•éŸ³ç»„ä»¶
    private var audioRecorder: AVAudioRecorder?
    private var audioEngine: AVAudioEngine?
    private var currentRecordingURL: URL?
    
    // Fun-ASRå»ºè®®çš„å‚æ•°
    private let silenceThreshold: Float = 0.01
    private let maxSentenceSilence: TimeInterval = 1.3  // Fun-ASRé»˜è®¤1300ms
    private let maxRecordingTime: TimeInterval = 10.0
    private let targetSampleRate: Double = 16000  // Fun-ASRæ”¯æŒ16kHz
    
    // çŠ¶æ€
    private var isRecording = false
    private var lastSpeechTime: Date?
    private var audioLevel: Float = 0.0
    private var silenceTimer: Timer?
    private var maxTimeTimer: Timer?
    
    init(asrService: QwenASRServiceProtocol, fileUploadService: FileUploadServiceProtocol) {
        self.asrService = asrService
        self.fileUploadService = fileUploadService
        super.init()
    }
    
    // MARK: - å…¬å¼€æŽ¥å£
    
    func startStreaming() async throws {
        guard !isRecording else { return }
        
        print("[ASR] ðŸŽ¤ å¼€å§‹è¯­éŸ³è¯†åˆ«ï¼ˆFun-ASRä¼˜åŒ–ç‰ˆï¼‰")
        
        try await setupAudioSession()
        try await startRecording()
        try await startAudioMonitoring()
        
        isRecording = true
        lastSpeechTime = nil
        
        // è®¾ç½®æœ€å¤§å½•éŸ³æ—¶é—´ä¿æŠ¤
        await MainActor.run { [weak self] in
            self?.maxTimeTimer = Timer.scheduledTimer(withTimeInterval: maxRecordingTime, repeats: false) { _ in
                Task { [weak self] in await self?.handleMaxTimeReached() }
            }
        }
        
        print("[ASR] âœ… å¼€å§‹å½•éŸ³ï¼ˆ16kHzé‡‡æ ·ï¼ŒVADæ–­å¥1.3ç§’ï¼‰")
    }
    
    func stopStreaming() async throws {
        guard isRecording else { return }
        
        isRecording = false
        
        // æ¸…ç†å®šæ—¶å™¨
        await MainActor.run {
            silenceTimer?.invalidate()
            silenceTimer = nil
            maxTimeTimer?.invalidate()
            maxTimeTimer = nil
        }
        
        // åœæ­¢å½•éŸ³å’Œç›‘å¬
        audioRecorder?.stop()
        audioEngine?.stop()
        audioEngine?.inputNode.removeTap(onBus: 0)
        
        // å¤„ç†å½•éŸ³ç»“æžœ
        await processRecordingResult()
        
        // æ¸…ç†
        audioRecorder = nil
        audioEngine = nil
        
        print("[ASR] ðŸ›‘ å½•éŸ³å·²åœæ­¢")
    }
    
    // MARK: - å†…éƒ¨å®žçŽ°
    
    private func setupAudioSession() async throws {
        let session = AVAudioSession.sharedInstance()
        try session.setCategory(.playAndRecord, mode: .default, options: [.defaultToSpeaker, .allowBluetoothA2DP])
        try session.setActive(true)
        
        // æŒ‰ç…§Fun-ASRå»ºè®®è®¾ç½®16kHzé‡‡æ ·çŽ‡
        try session.setPreferredSampleRate(targetSampleRate)
    }
    
    private func startRecording() async throws {
        let fileName = "voice_\(UUID().uuidString).m4a"
        currentRecordingURL = FileManager.default.temporaryDirectory.appendingPathComponent(fileName)
        
        // Fun-ASRå»ºè®®çš„éŸ³é¢‘æ ¼å¼è®¾ç½®
        let settings: [String: Any] = [
            AVFormatIDKey: Int(kAudioFormatMPEG4AAC),
            AVSampleRateKey: Int(targetSampleRate),  // 16kHz
            AVNumberOfChannelsKey: 1,  // å•å£°é“
            AVEncoderAudioQualityKey: AVAudioQuality.medium.rawValue
        ]
        
        guard let url = currentRecordingURL else {
            throw NSError(domain: "ASR", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ— æ³•åˆ›å»ºå½•éŸ³æ–‡ä»¶"])
        }
        
        audioRecorder = try AVAudioRecorder(url: url, settings: settings)
        audioRecorder?.record()
        
        print("[ASR] ðŸ“ å½•éŸ³æ–‡ä»¶: \(fileName)")
    }
    
    private func startAudioMonitoring() async throws {
        audioEngine = AVAudioEngine()
        guard let engine = audioEngine else { return }
        
        let inputNode = engine.inputNode
        let inputFormat = inputNode.outputFormat(forBus: 0)
        
        // ç›‘å¬éŸ³é¢‘æ•°æ®ï¼Œå®žçŽ°VAD
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: inputFormat) { [weak self] buffer, _ in
            Task { await self?.processAudioBuffer(buffer) }
        }
        
        engine.prepare()
        try engine.start()
    }
    
    private func processAudioBuffer(_ buffer: AVAudioPCMBuffer) async {
        guard isRecording else { return }
        
        // è®¡ç®—éŸ³é‡ï¼ˆVADï¼‰
        let currentLevel = calculateAudioLevel(buffer)
        audioLevel = currentLevel
        
        let now = Date()
        let isSpeaking = audioLevel > silenceThreshold
        
        if isSpeaking {
            // æ£€æµ‹åˆ°å£°éŸ³
            lastSpeechTime = now
            
            // æ˜¾ç¤ºæ­£åœ¨è¯†åˆ«çŠ¶æ€
            onPartialResult?("æ­£åœ¨è¯†åˆ«...")
            
            // å–æ¶ˆé™éŸ³è®¡æ—¶å™¨
            await MainActor.run {
                silenceTimer?.invalidate()
                silenceTimer = nil
            }
            
        } else if let lastSpeech = lastSpeechTime {
            // æ£€æµ‹é™éŸ³ - ä½¿ç”¨Fun-ASRå»ºè®®çš„1.3ç§’
            let silenceTime = now.timeIntervalSince(lastSpeech)
            
            if silenceTime >= maxSentenceSilence && silenceTimer == nil {
                await MainActor.run { [weak self] in
                    self?.silenceTimer = Timer.scheduledTimer(withTimeInterval: 0.2, repeats: false) { _ in
                        Task { [weak self] in await self?.handleSilenceDetected() }
                    }
                }
            }
        }
    }
    
    private func handleSilenceDetected() async {
        print("[ASR] ðŸ”‡ æ£€æµ‹åˆ°\(maxSentenceSilence)ç§’é™éŸ³ï¼Œåœæ­¢å½•éŸ³")
        try? await stopStreaming()
    }
    
    private func handleMaxTimeReached() async {
        print("[ASR] â° è¾¾åˆ°æœ€å¤§å½•éŸ³æ—¶é—´ï¼Œåœæ­¢å½•éŸ³")
        try? await stopStreaming()
    }
    
    private func processRecordingResult() async {
        guard let recordingURL = currentRecordingURL else { return }
        
        do {
            // æ£€æŸ¥æ–‡ä»¶
            let fileSize = try FileManager.default.attributesOfItem(atPath: recordingURL.path)[.size] as? Int ?? 0
            print("[ASR] ðŸ“Š å½•éŸ³æ–‡ä»¶å¤§å°: \(fileSize) bytes")
            
            guard fileSize > 8000 else {
                print("[ASR] âš ï¸ å½•éŸ³æ–‡ä»¶å¤ªå°ï¼Œå¯èƒ½æ²¡æœ‰è¯´è¯")
                return
            }
            
            // è°ƒç”¨ASRè¯†åˆ« - ä½¿ç”¨ä¸­æ–‡è¯­è¨€å‚æ•°
            print("[ASR] ðŸŽ¯ å¼€å§‹è¯†åˆ«...")
            let text = try await asrService.transcribe(audioURL: recordingURL, language: "zh")
            
            if !text.isEmpty {
                print("[ASR] âœ… è¯†åˆ«ç»“æžœ: \(text)")
                await MainActor.run {
                    // ç›´æŽ¥ä½œä¸ºæœ€ç»ˆç»“æžœï¼Œä¸å†æ£€æµ‹æ ‡ç‚¹ç¬¦å·
                    onFinalResult?(text)
                }
            } else {
                print("[ASR] âŒ è¯†åˆ«ç»“æžœä¸ºç©º")
            }
            
        } catch {
            print("[ASR] âŒ è¯†åˆ«å¤±è´¥: \(error)")
            // é™é»˜å¤„ç†é”™è¯¯ï¼Œä¸æ‰“æ‰°ç”¨æˆ·
        }
        
        // æ¸…ç†æ–‡ä»¶
        try? FileManager.default.removeItem(at: recordingURL)
    }
    
    private func calculateAudioLevel(_ buffer: AVAudioPCMBuffer) -> Float {
        guard let channelData = buffer.floatChannelData?[0] else { return 0.0 }
        
        var sum: Float = 0.0
        let frameLength = Int(buffer.frameLength)
        
        for i in 0..<frameLength {
            sum += abs(channelData[i])
        }
        
        return frameLength > 0 ? sum / Float(frameLength) : 0.0
    }
}
